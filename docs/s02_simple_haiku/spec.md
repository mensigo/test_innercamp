
# Общее

- агент пишет сообщения в stdout (короткие, визуально симпатичные) и в лог (подробные, для отладки)
- на каждом шаге есть свой лог префикс, который добавляется в начало каждого сообщения в рамках шага (напр., `[main]`)
- по ходу диалога все сообщения собираются и доступны в едином списке (истории сообщений)
- ...

todo длина сообщения, усечение
todo timeout=30
todo retries ?

# Запросы на LLM API

## 1. Запрос на генерацию /chat/completions

Отдельная функция: `post_chat_completions(payload: dict, verbose: bool = False) -> dict`

- `payload` обязательно содержит `messages`, может содержать доп. параметры (напр., `temperature`)
- если `payload` не содержит `model`, то устанавливается дефолтное значение `config.default_model` 
- если `verbose=True`, то в лог пишется `payload` (до запроса) и `response` (после успешного запроса) на уровне debug
- если при запросе происходит ошибка, то в лог пишется стектрейс ошибки на уровне critical и возвращается словарь вида `{"error": "<exception text>"}`
- если запрос проходит успешно, возвращается стандартный ответ вида [result_chatcomp.json](../../meta/gigachat/result_chatcomp.json)

## 2. Запрос на эмбеддинги /embeddings

Отдельная функция: `post_embeddings(payload: dict, verbose: bool = False) -> dict`

- `payload` обязательно содержит `input`
- если `payload` не содержит `model`, то устанавливается дефолтное значение `config.default_embedding_model` 
- если `verbose=True`, то в лог пишется `payload` (до запроса) и `response` (после успешного запроса) на уровне debug
- если при запросе происходит ошибка, то в лог пишется стектрейс ошибки на уровне critical и возвращается словарь вида `{"error": "< exception text >"}`
- если запрос проходит успешно, возвращается стандартный ответ вида [result_embeddings.json](../../meta/gigachat/result_embeddings.json)


# Основной сценарий

## Шаг 1. Запрос на агента.

Лог префикс: `[main]` 

1. Агент пишет справочное сообщение в stdout и статус "AgentStart" в лог (debug).

2. Агент запрашивает ввод от пользователя.

Если ввод содержит команду из списка `config.exit_commands`, то агент выводит "До свидания!" в stdout, пишет "AgentEnd" в лог (info) и завершает выполнение.

Если ввод содержит команду из списка `config.help_commands`, то агент выводит справочное сообщение в stdout, пишет "AgentHelp" в лог (info) и запрашивает ввод еще раз.

Получив сообщение от пользователя, агент добавляет его в историю сообщений.


## Шаг 2. Классификация интента

Лог префикс: `[cls]`

1. Агент пишет "Анализирую релевантность запроса.." в stdout и статус "AgentClassify" в лог (debug).

2. Агент анализирует историю сообщений и с помощью запроса на LLM определяет, относится ли интент пользователя к данному агенту.

Если запрос падает с ошибкой, то агент:
  - пишет "Ошибка при запросе LLM, завершаюсь.." в stdout
  - пишет "classify_intent // LLM Error: < error text >" в лог (critical)
  - завершает выполнение

Если произошла ошибка при парсинге ответа LLM, то агент:
  - пишет "Ошибка при разборе ответа LLM, завершаюсь.." в stdout
  - пишет "classify_intent // LLM Response Parse Error: < error text >" в лог (critical).
  - завершает выполнение

Если ответ обработан успешно, и запрос пользователя **не** соответствует функционалу агента, то агент:
  - пишет "Запрос не связан с функционалом агента." в stdout
  - выводит справочное сообщение в stdout
  - добавляет "Запрос не связан с функционалом агента." в историю сообщений
  - запрашивает новый ввод от пользователя

Если ответ обработан успешно, и запрос пользователя соответствует функционалу агента, то агент:
  - пишет "Запрос релевантен, думаю.." в stdout
  - добавляет "Запрос релевантен, думаю.." в историю сообщений
  - проходит на следующий Шаг 3


## Шаг 3. Выбор инструмента

Лог префикс: `[select]`

1. Агент пишет "Выбираю подходящий инструмент.." в stdout и статус "AgentSelect" в лог (debug).

2. Агент анализирует историю сообщений и с помощью запроса на LLM определяет, какой инструмент необходимо вызвать с какими параметрами.

Если запрос падает с ошибкой, то агент:
  - пишет "Ошибка при запросе LLM, завершаюсь.." в stdout
  - пишет "select_tool_call // LLM Error: < error text >" в лог (critical)
  - завершает выполнение

Если произошла ошибка при парсинге ответа LLM, то агент:
  - пишет "Ошибка при разборе ответа LLM, завершаюсь.." в stdout
  - пишет "select_tool_call // LLM Response Parse Error: < error text >" в лог (critical).
  - завершает выполнение

Если ответ обработан успешно, и **не** удалось определить инструмент, то агент:
  - пишет "Не удалось определить инструмент. Просьба переформулировать запрос." в stdout
  - добавляет "Запрос не связан с функционалом агента." в историю сообщений
  - запрашивает новый ввод от пользователя

Если ответ обработан успешно, и удалось определить инструмент, то агент:
  - пишет "Выбран инструмент < название > с параметрами < параметры, значения >" в stdout
  - добавляет соотв. строку в историю сообщений
  - проходит на следующий Шаг 4






## Config

| param                   | value                                         | description                      |
|:------------------------|:----------------------------------------------|:---------------------------------|
| EXIT_COMMANDS           | {'/exit', '/quit', '/q', 'exit', 'quit', 'q'} | Команды для выхода               |
| HELP_COMMANDS           | {'/help', 'help', '?'}                        | Команды для справки              |
| DEFAULT_MODEL           | GigaChat-2-Max                                | Дефолтная модель для генерации   |
| DEFAULT_EMBEDDING_MODEL | Embeddings                                    | Дефолтная модель для эмбеддингов |
| CONTEXT_HIST_LIMIT      | 10                                            |                                  |





